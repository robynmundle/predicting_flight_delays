{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "traditional-developer",
   "metadata": {},
   "source": [
    "# Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "guilty-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vulnerable-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mechanical-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('data/model_df_full.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sized-coordinate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>...</th>\n",
       "      <th>weekday</th>\n",
       "      <th>airline_delay</th>\n",
       "      <th>haul_length</th>\n",
       "      <th>dep_timeday</th>\n",
       "      <th>arr_timeday</th>\n",
       "      <th>delay_dep_h</th>\n",
       "      <th>delay_arr_h</th>\n",
       "      <th>busy_origin</th>\n",
       "      <th>busy_dest</th>\n",
       "      <th>origin_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>B6</td>\n",
       "      <td>3</td>\n",
       "      <td>6078</td>\n",
       "      <td>3</td>\n",
       "      <td>12478</td>\n",
       "      <td>JFK</td>\n",
       "      <td>14843</td>\n",
       "      <td>SJU</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date mkt_unique_carrier  mkt_carrier_fl_num  tail_num  \\\n",
       "0  2018-01-01                 B6                   3      6078   \n",
       "\n",
       "   op_carrier_fl_num  origin_airport_id origin  dest_airport_id dest  \\\n",
       "0                  3              12478    JFK            14843  SJU   \n",
       "\n",
       "   dep_time  ...  weekday  airline_delay  haul_length  dep_timeday  \\\n",
       "0    1138.0  ...        0              3            1            1   \n",
       "\n",
       "   arr_timeday  delay_dep_h  delay_arr_h  busy_origin  busy_dest  origin_delay  \n",
       "0            2            1            1            3        3.0             3  \n",
       "\n",
       "[1 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "neither-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_use_cols = ['arr_delay','origin', 'dest', 'diverted', 'crs_elapsed_time',\n",
    "       'actual_elapsed_time', 'distance', 'carrier_delay', 'weather_delay',\n",
    "       'nas_delay', 'security_delay', 'late_aircraft_delay', 'dep_hour',\n",
    "       'arr_hour', 'arr_hour_rank', 'month', 'month_rank', 'fl_num_speek_rank', 'carrier_rank',\n",
    "       'origin_precip', 'origin_snow', 'origin_windgust', 'origin_cloudcover',\n",
    "       'dest_precip', 'dest_snow', 'dest_windgust', 'dest_cloudcover',\n",
    "       'origin_precip_cat', 'origin_snow_cat', 'origin_windgust_cat',\n",
    "       'origin_cloud_cat', 'dest_precip_cat', 'dest_snow_cat',\n",
    "       'dest_windgust_cat', 'dest_cloud_cat', 'delay_flag', 'day', 'weekday',\n",
    "       'airline_delay', 'haul_length', 'dep_timeday', 'arr_timeday',\n",
    "       'delay_dep_h', 'delay_arr_h', 'busy_origin', 'busy_dest',\n",
    "       'origin_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "external-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns that might conceivably be used for training\n",
    "df = df[all_use_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-guide",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-class",
   "metadata": {},
   "source": [
    "### 01 - default params, without weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "equal-queen",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank', 'weekday',\n",
    "        'delay_dep_h', 'delay_arr_h', 'busy_origin', 'busy_dest', 'origin_delay']\n",
    "\n",
    "X = df[cols].to_numpy()\n",
    "y = df.arr_delay.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expensive-angola",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040294051146506416"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-burning",
   "metadata": {},
   "source": [
    "Result: 0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-diabetes",
   "metadata": {},
   "source": [
    "### 02 - default params, weather added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nearby-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank', 'weekday',\n",
    "        'delay_dep_h', 'delay_arr_h', 'busy_origin', 'busy_dest', 'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "X = df[cols].to_numpy()\n",
    "y = df.arr_delay.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "educational-madonna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.056038517946014554"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LinearRegression()\n",
    "lr2.fit(X_train, y_train)\n",
    "lr2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-motel",
   "metadata": {},
   "source": [
    "Score: 0.055\n",
    "Weather features improve predictive power. Let's try adding polynomials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-adolescent",
   "metadata": {},
   "source": [
    "### 03 - default params, weather added, polynomials - 2nd order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "about-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank', 'weekday',\n",
    "        'delay_dep_h', 'delay_arr_h', 'busy_origin', 'busy_dest', 'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "X = df[cols].to_numpy()\n",
    "y = df.arr_delay.to_numpy()\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "perceived-discrimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07539503827411442"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_03 = LinearRegression()\n",
    "model_03.fit(X_train, y_train)\n",
    "model_03.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "encouraging-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'models/model_03.sav'\n",
    "# pickle.dump(model_03, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-raise",
   "metadata": {},
   "source": [
    "Score = 0.076 - better again. How does this compare to the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "competent-benjamin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07680762786486939"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_03.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-ozone",
   "metadata": {},
   "source": [
    "0.078. About the same, so we're not overfitting yet. Let's try 3rd-order polynomials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-potential",
   "metadata": {},
   "source": [
    "### 04 - default params, weather added, polynomials - 3rd order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fallen-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank', 'weekday',\n",
    "        'delay_dep_h', 'delay_arr_h', 'busy_origin', 'busy_dest', 'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "X = df[cols].to_numpy()\n",
    "y = df.arr_delay.to_numpy()\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "available-trust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arr_hour_rank</th>\n",
       "      <th>month_rank</th>\n",
       "      <th>haul_length</th>\n",
       "      <th>fl_num_speek_rank</th>\n",
       "      <th>carrier_rank</th>\n",
       "      <th>weekday</th>\n",
       "      <th>delay_dep_h</th>\n",
       "      <th>delay_arr_h</th>\n",
       "      <th>busy_origin</th>\n",
       "      <th>busy_dest</th>\n",
       "      <th>origin_delay</th>\n",
       "      <th>origin_precip_cat</th>\n",
       "      <th>origin_snow_cat</th>\n",
       "      <th>origin_windgust_cat</th>\n",
       "      <th>origin_cloud_cat</th>\n",
       "      <th>dest_precip_cat</th>\n",
       "      <th>dest_snow_cat</th>\n",
       "      <th>dest_windgust_cat</th>\n",
       "      <th>dest_cloud_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827097</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827098</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827099</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827100</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827101</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "      <td>3.909477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>827102 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        arr_hour_rank  month_rank  haul_length  fl_num_speek_rank  \\\n",
       "0                   1           0            1                1.0   \n",
       "1                   1           0            1                0.0   \n",
       "2                   1           0            2                0.0   \n",
       "3                   2           0            0                1.0   \n",
       "4                   1           0            0                2.0   \n",
       "...               ...         ...          ...                ...   \n",
       "827097              2           2            0                2.0   \n",
       "827098              0           2            0                2.0   \n",
       "827099              2           2            0                3.0   \n",
       "827100              1           2            0                4.0   \n",
       "827101              2           2            0                2.0   \n",
       "\n",
       "        carrier_rank  weekday  delay_dep_h  delay_arr_h  busy_origin  \\\n",
       "0                  0        0            1            1            3   \n",
       "1                  0        0            0            1            4   \n",
       "2                  0        0            3            3            3   \n",
       "3                  0        0            3            3            3   \n",
       "4                  0        0            1            1            3   \n",
       "...              ...      ...          ...          ...          ...   \n",
       "827097             2        2            3            2            4   \n",
       "827098             2        2            0            0            4   \n",
       "827099             2        2            3            3            4   \n",
       "827100             2        2            2            2            4   \n",
       "827101             2        2            2            2            4   \n",
       "\n",
       "        busy_dest  origin_delay  origin_precip_cat  origin_snow_cat  \\\n",
       "0             3.0             3                0.0              0.0   \n",
       "1             3.0             1                0.0              0.0   \n",
       "2             3.0             3                0.0              0.0   \n",
       "3             3.0             3                0.0              0.0   \n",
       "4             3.0             3                0.0              0.0   \n",
       "...           ...           ...                ...              ...   \n",
       "827097        2.0             2                1.0              0.0   \n",
       "827098        4.0             1                0.0              0.0   \n",
       "827099        3.0             2                1.0              0.0   \n",
       "827100        4.0             2                1.0              0.0   \n",
       "827101        3.0             2                1.0              0.0   \n",
       "\n",
       "        origin_windgust_cat  origin_cloud_cat  dest_precip_cat  dest_snow_cat  \\\n",
       "0                  3.000000               0.0         3.909477       3.909477   \n",
       "1                  3.909477               2.0         0.000000       0.000000   \n",
       "2                  3.000000               0.0         3.909477       3.909477   \n",
       "3                  3.000000               0.0         3.909477       3.909477   \n",
       "4                  3.000000               0.0         3.909477       3.909477   \n",
       "...                     ...               ...              ...            ...   \n",
       "827097             3.000000               1.0         3.909477       3.909477   \n",
       "827098             1.000000               0.0         3.909477       3.909477   \n",
       "827099             3.000000               1.0         3.909477       3.909477   \n",
       "827100             3.000000               1.0         0.000000       0.000000   \n",
       "827101             3.000000               1.0         3.909477       3.909477   \n",
       "\n",
       "        dest_windgust_cat  dest_cloud_cat  \n",
       "0                3.909477        3.909477  \n",
       "1                3.000000        0.000000  \n",
       "2                3.909477        3.909477  \n",
       "3                3.909477        3.909477  \n",
       "4                3.909477        3.909477  \n",
       "...                   ...             ...  \n",
       "827097           3.909477        3.909477  \n",
       "827098           3.909477        3.909477  \n",
       "827099           3.909477        3.909477  \n",
       "827100           2.000000        0.000000  \n",
       "827101           3.909477        3.909477  \n",
       "\n",
       "[827102 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convertible-motor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08389678808424572"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_04 = LinearRegression()\n",
    "model_04.fit(X_train, y_train)\n",
    "model_04.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "controlling-diagram",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707.1344100740351"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_04.predict(X_test)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "static-escape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.591998986049077"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "previous-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'models/model_04.sav'\n",
    "# pickle.dump(model_04, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-interaction",
   "metadata": {},
   "source": [
    "0.083 - even better. How does it compare to the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "regular-chicago",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08888570183677313"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_04.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-prime",
   "metadata": {},
   "source": [
    "0.089 - It fits the training set slightly better than the test set. \n",
    "But that took quite a long time, so let's see if we can trim down the features and get a similar result. That might also deal with the overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-warner",
   "metadata": {},
   "source": [
    "### 05 - Detect feature importances using RandomForestRegression on a sample of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "married-prize",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mask = np.random.rand(len(X_train)) < 0.1\n",
    "X_train_sample = X_train[sample_mask,:]\n",
    "y_train_sample = y_train[sample_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "upset-grant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=50)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_05 = RandomForestRegressor(n_estimators=50)\n",
    "model_05.fit(X_train_sample, y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cutting-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'models/model_05.sav'\n",
    "# pickle.dump(model_05, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "destroyed-peripheral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06853453861644376\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_05.predict(X_test)\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-passing",
   "metadata": {},
   "source": [
    "No."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-elevation",
   "metadata": {},
   "source": [
    "### 06 - default params, weather added, polynomials - 3rd order; some features removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "buried-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank',\n",
    "        'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "X = df[cols].to_numpy()\n",
    "y = df.arr_delay.to_numpy()\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "insured-rotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07899706462415756"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_06 = LinearRegression()\n",
    "model_06.fit(X_train, y_train)\n",
    "model_06.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-start",
   "metadata": {},
   "source": [
    "0.079"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "confidential-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'models/model_06.sav'\n",
    "# pickle.dump(model_06, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-magnitude",
   "metadata": {},
   "source": [
    "### 07 - Repeat 06 but Scale Features First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank',\n",
    "        'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(df[cols])\n",
    "y = df['arr_delay'].to_numpy()\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "grand-sender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07852707824026739"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_07 = LinearRegression()\n",
    "model_07.fit(X_train, y_train)\n",
    "model_07.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-enhancement",
   "metadata": {},
   "source": [
    "0.079 on the test data vs. 0.08 on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "electrical-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'models/model_07.sav'\n",
    "# pickle.dump(model_07, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "selected-steel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08082897931570343"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_07.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-austria",
   "metadata": {},
   "source": [
    "### 08 - Hail Mary Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "racial-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank',\n",
    "        'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "X = df[cols].to_numpy()\n",
    "y = df.arr_delay.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model_08 = RandomForestRegressor()\n",
    "model_08.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "behavioral-bowling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028683238835234715"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_08.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-diabetes",
   "metadata": {},
   "source": [
    "0.029 - bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'models/model_07.sav'\n",
    "# pickle.dump(model_07, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-hanging",
   "metadata": {},
   "source": [
    "# 09 - Elastic Net with 2nd order polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "junior-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank',\n",
    "        'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(df[cols])\n",
    "y = df['arr_delay'].to_numpy()\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "chronic-heading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_09 = ElasticNet()\n",
    "model_09.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "french-astrology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04668579077470347"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_09.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-mountain",
   "metadata": {},
   "source": [
    "0.045. More evidence that overfitting isn't the problem - regularisation makes it worse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-constitution",
   "metadata": {},
   "source": [
    "### 10 - Elastic Net with 3rd order polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "opposed-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank',\n",
    "        'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(df[cols])\n",
    "y = df['arr_delay'].to_numpy()\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "naughty-colony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10 = ElasticNet()\n",
    "model_10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "vocational-hundred",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05783878467534331"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_10.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "straight-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'models/model_10.sav'\n",
    "# pickle.dump(model_10, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-anthony",
   "metadata": {},
   "source": [
    "## 11 - All features; Elastic Net with 3rd order polynomials; GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "internal-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank', 'weekday',\n",
    "        'delay_dep_h', 'delay_arr_h', 'busy_origin', 'busy_dest', 'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(df[cols])\n",
    "y = df['arr_delay'].to_numpy()\n",
    "\n",
    "poly = PolynomialFeatures(3)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-parks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 176648779.21986526, tolerance: 40819.171875371125\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ......................alpha=0.001, l1_ratio=0.9; total time=40.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 176420017.52974927, tolerance: 40800.9355918541\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ......................alpha=0.001, l1_ratio=0.9; total time=35.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 176881577.3113045, tolerance: 40890.41372134354\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ......................alpha=0.001, l1_ratio=0.9; total time=38.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 176790216.42974746, tolerance: 40836.23588497881\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ......................alpha=0.001, l1_ratio=0.9; total time=34.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 175898189.97859564, tolerance: 40881.77572898316\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ......................alpha=0.001, l1_ratio=0.9; total time=36.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 181249810.64397278, tolerance: 40819.171875371125\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ......................alpha=0.001, l1_ratio=0.5; total time=41.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 181327484.011452, tolerance: 40800.9355918541\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ......................alpha=0.001, l1_ratio=0.5; total time=36.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 181642896.02653807, tolerance: 40890.41372134354\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ......................alpha=0.001, l1_ratio=0.5; total time=38.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 181426989.3801692, tolerance: 40836.23588497881\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ......................alpha=0.001, l1_ratio=0.5; total time=39.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omlean/anaconda3/envs/lighthouse/lib/python3.6/site-packages/sklearn/linear_model/_coordinate_descent.py:532: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 181059724.7548719, tolerance: 40881.77572898316\n",
      "  positive)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ......................alpha=0.001, l1_ratio=0.5; total time=39.4min\n"
     ]
    }
   ],
   "source": [
    "params = {'alpha': [0.001, 0.01, 0.1],\n",
    "         'l1_ratio': [0.9, 0.5, 0.1]}\n",
    "model_11 = GridSearchCV(estimator=ElasticNet(), param_grid=params, verbose=3)\n",
    "model_11.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'models/model_11.sav'\n",
    "# pickle.dump(model_11, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-grounds",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
