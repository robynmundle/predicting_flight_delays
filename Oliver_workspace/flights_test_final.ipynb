{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "opponent-referral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "from datetime import datetime, date, time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "verified-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/raw_flights_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "warming-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns for hour of departure and arrival \n",
    "def hour(t):\n",
    "    s = str(t)\n",
    "    if len(s) < 3:\n",
    "        return 0\n",
    "    elif len(s) == 3:\n",
    "        return int(s[0])\n",
    "    elif len(s) == 4:\n",
    "        if int(s[:2]) == 24:\n",
    "            return 0\n",
    "        else:\n",
    "            return int(s[:2])\n",
    "\n",
    "df['dep_hour'] = df.crs_dep_time.apply(hour)\n",
    "df['arr_hour'] = df.crs_arr_time.apply(hour)\n",
    "\n",
    "hour_ranks = pd.read_csv('data/arr_hour_ranks.csv').set_index('arr_hour').rename(columns={'arr_delay':'arr_hour_rank'})\n",
    "df = df.join(hour_ranks, how='left', on='arr_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "false-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add month column\n",
    "def month(datestring):\n",
    "    date = datetime.strptime(datestring, \"%Y-%m-%d\")\n",
    "    return date.month\n",
    "\n",
    "df['month'] = df.fl_date.apply(month)\n",
    "\n",
    "month_ranks = pd.read_csv('data/month_ranks.csv').rename(columns={'arr_delay':'month_rank'}).set_index('month')\n",
    "df = df.join(month_ranks, how='left', on='month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demonstrated-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add flight number delay ranks\n",
    "fl_num_ranks = pd.read_csv('data/fl_num_ranks.csv', index_col=['op_unique_carrier', 'op_carrier_fl_num']).rename(columns={'arr_delay': 'fl_num_speek_rank'})\n",
    "df = df.join(fl_num_ranks, how='left', on=['op_unique_carrier', 'op_carrier_fl_num'])\n",
    "df.fl_num_speek_rank.fillna(value=2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "italic-offer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>...</th>\n",
       "      <th>dup</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>dep_hour</th>\n",
       "      <th>arr_hour</th>\n",
       "      <th>arr_hour_rank</th>\n",
       "      <th>month</th>\n",
       "      <th>month_rank</th>\n",
       "      <th>fl_num_speek_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>WN</td>\n",
       "      <td>5888</td>\n",
       "      <td>WN</td>\n",
       "      <td>N951WN</td>\n",
       "      <td>5888</td>\n",
       "      <td>13891</td>\n",
       "      <td>ONT</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>363</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "0  2020-01-01                 WN                 WN          WN   \n",
       "\n",
       "   mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "0                5888                WN   N951WN               5888   \n",
       "\n",
       "   origin_airport_id origin  ... dup  crs_elapsed_time flights distance  \\\n",
       "0              13891    ONT  ...   N                95       1      363   \n",
       "\n",
       "   dep_hour  arr_hour arr_hour_rank  month  month_rank  fl_num_speek_rank  \n",
       "0        18        19             2      1           0                2.0  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "challenging-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add carrier rank\n",
    "carr_rank = pd.read_csv('data/carrier_ranks.csv').set_index('mkt_unique_carrier').rename(columns={'arr_delay': 'carrier_rank'})\n",
    "df = df.join(carr_rank, how='left', on='mkt_unique_carrier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-membrane",
   "metadata": {},
   "source": [
    "## Weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "involved-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all available weather data into a dataframe\n",
    "directory = \"vc_api/weather-data/\"\n",
    "files = [file for file in os.listdir(directory) if not file.startswith(\".\")]\n",
    "\n",
    "airport = []\n",
    "date = []\n",
    "precip = []\n",
    "snow = []\n",
    "snowdepth = []\n",
    "windgust = []\n",
    "cloudcover = []\n",
    "icon = []\n",
    "\n",
    "for file in files:\n",
    "    with open(directory+file) as f:\n",
    "        j = json.load(f)\n",
    "    airport.append(file[:3]) # airport code\n",
    "    date.append(j['days'][0]['datetime'])\n",
    "    precip.append(j['days'][0]['precip'])\n",
    "    snow.append(j['days'][0]['snow'])\n",
    "#     snowdepth.append(j['days'][0]['snowdepth'])\n",
    "    windgust.append(j['days'][0]['windgust'])\n",
    "    cloudcover.append(j['days'][0]['cloudcover'])\n",
    "#     icon.append(j['days'][0]['icon'])\n",
    "\n",
    "# create DataFrame\n",
    "d = {'origin': airport, 'fl_date': date, 'precip': precip, 'snow': snow,\n",
    "     'windgust': windgust, 'cloudcover': cloudcover}\n",
    "weather_df = pd.DataFrame(data=d).set_index(['fl_date', 'origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "south-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join weather columns by origin and destination\n",
    "df = df.join(weather_df, on=['fl_date', 'origin'], how='left').rename(columns={'precip':'origin_precip',\n",
    "                                                                              'snow':'origin_snow',\n",
    "                                                                              'windgust':'origin_windgust',\n",
    "                                                                              'cloudcover': 'origin_cloudcover'})\n",
    "df = df.join(weather_df, on=['fl_date', 'dest'], how='left').rename(columns={'precip':'dest_precip',\n",
    "                                                                              'snow':'dest_snow',\n",
    "                                                                              'windgust':'dest_windgust',\n",
    "                                                                              'cloudcover': 'dest_cloudcover'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "asian-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin weather into levels\n",
    "def precip_bins(val):\n",
    "    if np.isnan(val):\n",
    "        return np.nan\n",
    "    elif val > 79:\n",
    "        return 3\n",
    "    elif val > 39:\n",
    "        return 2\n",
    "    elif val > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def snow_bins(val):\n",
    "    if np.isnan(val):\n",
    "        return np.nan\n",
    "    elif val > 1.8:\n",
    "        return 2\n",
    "    elif val > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def wind_bins(val):\n",
    "    if np.isnan(val):\n",
    "        return np.nan\n",
    "    elif val > 46:\n",
    "        return 3\n",
    "    elif val > 35:\n",
    "        return 2\n",
    "    elif val > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def cloud_bins(val):\n",
    "    if np.isnan(val):\n",
    "        return np.nan\n",
    "    elif val > 71:\n",
    "        return 2\n",
    "    elif val > 47:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['origin_precip_cat'] = df['origin_precip'].apply(precip_bins)\n",
    "df['origin_snow_cat'] = df['origin_snow'].apply(snow_bins)\n",
    "df['origin_windgust_cat'] = df['origin_windgust'].apply(wind_bins)\n",
    "df['origin_cloud_cat'] = df['origin_cloudcover'].apply(cloud_bins)\n",
    "df['dest_precip_cat'] = df['dest_precip'].apply(precip_bins)\n",
    "df['dest_snow_cat'] = df['dest_snow'].apply(snow_bins)\n",
    "df['dest_windgust_cat'] = df['dest_windgust'].apply(wind_bins)\n",
    "df['dest_cloud_cat'] = df['dest_cloudcover'].apply(cloud_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "favorite-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('data/my_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-designation",
   "metadata": {},
   "source": [
    "## Robyn's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bottom-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRS_ELAPSED_TIME --> HAUL_LENGTH\n",
    "def haul(df, col):\n",
    "    '''Determine if flight length is SHORT, MEDIUM or LONG based on expected elapsed flight time. \n",
    "            Input: \n",
    "            (0) df containing flight information, \n",
    "            (1) column containing the elapsed flight time in minutes   \n",
    "            Output:   'haul_length' column determining haul length category per row in df'''\n",
    "    global length\n",
    "    length=[]\n",
    "    for i in df[col]:\n",
    "        if i < (3*60): # up to 3 hours\n",
    "            length.append(0) # 0 = SHORT HAUL\n",
    "        elif (i >= (3*60)) and (i < (6*60)): # 3-6 hours\n",
    "            length.append(1) # 1 = MEDIUM HAUL\n",
    "        elif i >= (6*60):# 6+ hours\n",
    "            length.append(2) # 2 = LONG HAUL\n",
    "    df['haul_length'] = length\n",
    "# example of implementation: haul(flight10k, 'crs_elapsed_time')\n",
    "\n",
    "# CRS_DEP_TIME (hhmm) --> CRS_DEP_TIME (hh) -- to be used within time_day function\n",
    "def gethour(df,col):\n",
    "    '''Convert hhmm to hh (24-hr) hour-only output\n",
    "            Input: \n",
    "            (0) df containing flight information, \n",
    "            (1) column containing the hhmm time                  \n",
    "            Output:   rewrite on input column in rounded hh format'''\n",
    "    values = []\n",
    "    for i in df[col]:\n",
    "        mins = (i % 100) / 60 \n",
    "        hour = i // 100\n",
    "        hh = round(hour+mins)\n",
    "        values.append(hh)\n",
    "    df[col] = values\n",
    "# example of implementation: gethour(flight10k, 'crs_dep_time')\n",
    "\n",
    "# CRS_DEP/ARR_TIME (hhmm) --> hot encoded categorical time of day 'morning, aft...' \n",
    "def time_day(df, col):\n",
    "    ''' Input:\n",
    "            (0) df containing flight information\n",
    "            (1) corresponding column of time of flight (i.e. departure or arrival) (format hhmm)\n",
    "        Output:   rewrite of time column into categorical MORNING, AFTERNOON, EVENING, or OVERNIGHT'''\n",
    "    gethour(df, col)\n",
    "    timeday = []\n",
    "    for i in df[col]:\n",
    "        if (i>=23) or (i<5):\n",
    "            timeday.append(0) # 0 = OVERNIGHT\n",
    "        elif (i>=5) and (i<12):\n",
    "            timeday.append(1) # 1 = MORNING\n",
    "        elif (i>=12) and (i<18):\n",
    "            timeday.append(2) # 2 = AFTERNOON\n",
    "        elif (i>=18) and (i<23):\n",
    "            timeday.append(3) # 3 = EVENING\n",
    "    return timeday\n",
    "# example of implementation: time_day(flight10k, 'crs_dep_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sensitive-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_rating = pd.read_csv('data/airline_delay_rating.csv', index_col=0)\n",
    "origin_traffic = pd.read_csv('data/origin_traffic_rating.csv', index_col=0)\n",
    "origin_delay = pd.read_csv('data/origin_delay_rating.csv', index_col=0)\n",
    "dest_traffic = pd.read_csv('data/dest_traffic_rating.csv', index_col=0)\n",
    "delay_dep_h = pd.read_csv('data/crs_dep_time_delay_rating.csv', index_col=0)\n",
    "delay_arr_h = pd.read_csv('data/crs_arr_time_delay_rating.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "enormous-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = df[df.crs_elapsed_time.isnull()].index\n",
    "# df.drop(mask.values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thousand-arthur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fl_date', 'mkt_unique_carrier', 'branded_code_share', 'mkt_carrier',\n",
       "       'mkt_carrier_fl_num', 'op_unique_carrier', 'tail_num',\n",
       "       'op_carrier_fl_num', 'origin_airport_id', 'origin', 'origin_city_name',\n",
       "       'dest_airport_id', 'dest', 'dest_city_name', 'crs_dep_time',\n",
       "       'crs_arr_time', 'dup', 'crs_elapsed_time', 'flights', 'distance',\n",
       "       'dep_hour', 'arr_hour', 'arr_hour_rank', 'month', 'month_rank',\n",
       "       'fl_num_speek_rank', 'carrier_rank', 'origin_precip', 'origin_snow',\n",
       "       'origin_windgust', 'origin_cloudcover', 'dest_precip', 'dest_snow',\n",
       "       'dest_windgust', 'dest_cloudcover', 'origin_precip_cat',\n",
       "       'origin_snow_cat', 'origin_windgust_cat', 'origin_cloud_cat',\n",
       "       'dest_precip_cat', 'dest_snow_cat', 'dest_windgust_cat',\n",
       "       'dest_cloud_cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "animal-exception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150623, 51)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A - if this is a training dataset, we need arr_delay as our target variable so use this first block of code\n",
    "model_df = df.copy()\n",
    "# B - if this is a testing dataset, we will not have arr_delay and cannot include it\n",
    "#model_df = flights[['tail_num','op_carrier_fl_num','fl_date','op_unique_carrier','origin','dest','crs_dep_time','crs_arr_time','crs_elapsed_time','distance']]\n",
    "\n",
    "# first regression will be simple-- is the flight going to be delayed or not?\n",
    "if 'arr_delay' in model_df:\n",
    "    model_df['delay_flag'] = model_df['arr_delay'].map(lambda x: 0 if x <= 0 else 1)\n",
    "    arr_delay = model_df['arr_delay']\n",
    "#     model_df.drop(columns='arr_delay', inplace=True)\n",
    "\n",
    "# label encode tail_num for identification of the flight later\n",
    "le = preprocessing.LabelEncoder()\n",
    "tail_num = model_df['tail_num'].values\n",
    "model_df['tail_num'] = le.fit_transform(tail_num)\n",
    "\n",
    "# convert date to datetime in order to grab the month\n",
    "model_df['fl_date'] = pd.to_datetime(model_df['fl_date'])\n",
    "#model_df['year'] = model_df['fl_date'].dt.year\n",
    "model_df['month'] = model_df['fl_date'].dt.month\n",
    "model_df['day'] = model_df['fl_date'].dt.day\n",
    "model_df['weekday'] = model_df['fl_date'].dt.dayofweek\n",
    "# model_df.drop(columns='fl_date', inplace=True) # this won't be needed after we got month\n",
    "\n",
    "# set delay rating based on expected performance of the airline\n",
    "model_df = model_df.merge(airline_rating, left_on='op_unique_carrier', right_on='airline', how='left')\n",
    "model_df.drop(columns=['op_unique_carrier','airline'],inplace=True) \n",
    "\n",
    "# obtain haul length of the flight using haul function defined above\n",
    "haul(model_df, 'crs_elapsed_time')\n",
    "#model_df.drop(columns=['crs_elapsed_time'],inplace=True)\n",
    "\n",
    "# new column of categorical time of day information using time_day function defined above as well as expected delays relating to the time of day departure\n",
    "model_df['dep_timeday'] = time_day(model_df, 'crs_dep_time')\n",
    "model_df['arr_timeday'] = time_day(model_df, 'crs_arr_time')\n",
    "model_df = model_df.merge(delay_dep_h, left_on='crs_dep_time', right_on='crs_dep_time', how='left')\n",
    "model_df = model_df.merge(delay_arr_h, left_on='crs_arr_time', right_on='crs_arr_time', how='left')\n",
    "model_df.drop(columns=['crs_dep_time','crs_arr_time'],inplace=True)\n",
    "\n",
    "# classify the expected traffic of the origin and departure airports\n",
    "model_df = model_df.merge(origin_traffic, left_on='origin', right_on='origin', how='left')\n",
    "model_df = model_df.merge(dest_traffic, left_on='dest', right_on='dest', how='left')\n",
    "model_df = model_df.fillna(model_df['busy_origin'].mean())\n",
    "model_df = model_df.merge(origin_delay, left_on='origin', right_on='origin', how='left')\n",
    "# model_df.drop(columns=['origin','dest'],inplace=True)\n",
    "\n",
    "#if 'arr_delay' in model_df:\n",
    "#    training_full = model_df.copy(deep=True)\n",
    "#    model_df.drop(columns='arr_delay', inplace=True)\n",
    "\n",
    "# have a look at the dataset\n",
    "model_df.head()\n",
    "model_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afraid-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_df.to_csv('data/model_df_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "skilled-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save progress\n",
    "# model_df.to_csv('data/flights_test_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-brake",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "interested-textbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load best model\n",
    "model = pickle.load(open('models/model_04.sav', 'rb'))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "demanding-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['arr_hour_rank', 'month_rank', 'haul_length', 'fl_num_speek_rank', 'carrier_rank', 'weekday',\n",
    "        'delay_dep_h', 'delay_arr_h', 'busy_origin', 'busy_dest', 'origin_delay',\n",
    "       'origin_precip_cat', 'origin_snow_cat',\n",
    "       'origin_windgust_cat', 'origin_cloud_cat', 'dest_precip_cat',\n",
    "       'dest_snow_cat', 'dest_windgust_cat', 'dest_cloud_cat']\n",
    "\n",
    "X = model_df[cols].to_numpy()\n",
    "\n",
    "poly = preprocessing.PolynomialFeatures(3)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "baking-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "underlying-teach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.11923725e+07, -2.11923883e+07, -2.11923625e+07, ...,\n",
       "        2.41693014e+00,  4.96139689e+07,  1.08851661e+01])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "natural-castle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150623\n",
      "150623\n"
     ]
    }
   ],
   "source": [
    "print(len(df))\n",
    "print(len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ranking-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.Series(y_pred)\n",
    "df_sub = pd.concat([df, pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "naughty-coalition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([            'fl_date',  'mkt_unique_carrier',  'branded_code_share',\n",
       "               'mkt_carrier',  'mkt_carrier_fl_num',   'op_unique_carrier',\n",
       "                  'tail_num',   'op_carrier_fl_num',   'origin_airport_id',\n",
       "                    'origin',    'origin_city_name',     'dest_airport_id',\n",
       "                      'dest',      'dest_city_name',        'crs_dep_time',\n",
       "              'crs_arr_time',                 'dup',    'crs_elapsed_time',\n",
       "                   'flights',            'distance',            'dep_hour',\n",
       "                  'arr_hour',       'arr_hour_rank',               'month',\n",
       "                'month_rank',   'fl_num_speek_rank',        'carrier_rank',\n",
       "             'origin_precip',         'origin_snow',     'origin_windgust',\n",
       "         'origin_cloudcover',         'dest_precip',           'dest_snow',\n",
       "             'dest_windgust',     'dest_cloudcover',   'origin_precip_cat',\n",
       "           'origin_snow_cat', 'origin_windgust_cat',    'origin_cloud_cat',\n",
       "           'dest_precip_cat',       'dest_snow_cat',   'dest_windgust_cat',\n",
       "            'dest_cloud_cat',                     0],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "twenty-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub[['fl_date', 'mkt_carrier', 'mkt_carrier_fl_num','origin','dest',0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "coupled-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df_sub.rename(columns={0: 'predicted_delay'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "early-nevada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-electricity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
