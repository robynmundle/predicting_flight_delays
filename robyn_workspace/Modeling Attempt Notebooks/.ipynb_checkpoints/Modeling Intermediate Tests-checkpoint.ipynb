{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expressed-ordinary",
   "metadata": {},
   "source": [
    "copy from colab to run xgboost instead of random forest on the delay range class only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "following-berkeley",
   "metadata": {},
   "source": [
    "Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "threaded-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "from datetime import datetime, date, time\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apart-brazilian",
   "metadata": {},
   "source": [
    "Completed Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seven-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRS_ELAPSED_TIME --> HAUL_LENGTH\n",
    "def haul(df, col):\n",
    "    '''Determine if flight length is SHORT, MEDIUM or LONG based on expected elapsed flight time. \n",
    "            Input: \n",
    "            (0) df containing flight information, \n",
    "            (1) column containing the elapsed flight time in minutes   \n",
    "            Output:   'haul_length' column determining haul length category per row in df'''\n",
    "    length=[]\n",
    "    for i in df[col]:\n",
    "        if i < (3*60): # up to 3 hours\n",
    "            length.append(0) # 0 = SHORT HAUL\n",
    "        elif (i >= (3*60)) and (i < (6*60)): # 3-6 hours\n",
    "            length.append(1) # 1 = MEDIUM HAUL\n",
    "        elif i >= (6*60):# 6+ hours\n",
    "            length.append(2) # 2 = LONG HAUL\n",
    "    df['haul_length'] = length\n",
    "# example of implementation: haul(flight10k, 'crs_elapsed_time')\n",
    "\n",
    "# CRS_DEP_TIME (hhmm) --> CRS_DEP_TIME (hh) -- to be used within time_day function\n",
    "def gethour(df,col):\n",
    "    '''Convert hhmm to hh (24-hr) hour-only output\n",
    "            Input: \n",
    "            (0) df containing flight information, \n",
    "            (1) column containing the hhmm time                  \n",
    "            Output:   rewrite on input column in rounded hh format'''\n",
    "    values = []\n",
    "    for i in df[col]:\n",
    "        mins = (i % 100) / 60 \n",
    "        hour = i // 100\n",
    "        hh = round(hour+mins)\n",
    "        values.append(hh)\n",
    "    df[col] = values\n",
    "# example of implementation: gethour(flight10k, 'crs_dep_time')\n",
    "\n",
    "# CRS_DEP/ARR_TIME (hhmm) --> hot encoded categorical time of day 'morning, aft...' \n",
    "def time_day(df, col):\n",
    "    ''' Input:\n",
    "            (0) df containing flight information\n",
    "            (1) corresponding column of time of flight (i.e. departure or arrival) (format hhmm)\n",
    "        Output:   rewrite of time column into categorical MORNING, AFTERNOON, EVENING, or OVERNIGHT'''\n",
    "    gethour(df, col)\n",
    "    timeday = []\n",
    "    for i in df[col]:\n",
    "        if (i>=23) or (i<5):\n",
    "            timeday.append(0) # 0 = OVERNIGHT\n",
    "        elif (i>=5) and (i<12):\n",
    "            timeday.append(1) # 1 = MORNING\n",
    "        elif (i>=12) and (i<18):\n",
    "            timeday.append(2) # 2 = AFTERNOON\n",
    "        elif (i>=18) and (i<23):\n",
    "            timeday.append(3) # 3 = EVENING\n",
    "    return timeday\n",
    "# example of implementation: time_day(flight10k, 'crs_dep_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-hundred",
   "metadata": {},
   "source": [
    "CSVs of Pre-Evaluated Features (Historical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "careful-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "airline_rating = pd.read_csv('data/airline_delay_rating.csv', index_col=0)\n",
    "origin_traffic = pd.read_csv('data/origin_traffic_rating.csv', index_col=0)\n",
    "origin_delay = pd.read_csv('data/origin_delay_rating.csv', index_col=0)\n",
    "dest_traffic = pd.read_csv('data/dest_traffic_rating.csv', index_col=0)\n",
    "delay_dep_h = pd.read_csv('data/crs_dep_time_delay_rating.csv', index_col=0)\n",
    "delay_arr_h = pd.read_csv('data/crs_arr_time_delay_rating.csv', index_col=0)\n",
    "weather_df = pd.read_csv('data/weather_df_monthlymean_bins.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-trunk",
   "metadata": {},
   "source": [
    "Open CSV of Flight Training Information to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "appointed-laptop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fl_date</th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>branded_code_share</th>\n",
       "      <th>mkt_carrier</th>\n",
       "      <th>mkt_carrier_fl_num</th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>tail_num</th>\n",
       "      <th>op_carrier_fl_num</th>\n",
       "      <th>origin_airport_id</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>dest_airport_id</th>\n",
       "      <th>dest</th>\n",
       "      <th>dest_city_name</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>taxi_out</th>\n",
       "      <th>wheels_off</th>\n",
       "      <th>wheels_on</th>\n",
       "      <th>taxi_in</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>cancellation_code</th>\n",
       "      <th>diverted</th>\n",
       "      <th>dup</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>actual_elapsed_time</th>\n",
       "      <th>air_time</th>\n",
       "      <th>flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>carrier_delay</th>\n",
       "      <th>weather_delay</th>\n",
       "      <th>nas_delay</th>\n",
       "      <th>security_delay</th>\n",
       "      <th>late_aircraft_delay</th>\n",
       "      <th>first_dep_time</th>\n",
       "      <th>total_add_gtime</th>\n",
       "      <th>longest_add_gtime</th>\n",
       "      <th>no_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-26</td>\n",
       "      <td>DL</td>\n",
       "      <td>DL_CODESHARE</td>\n",
       "      <td>DL</td>\n",
       "      <td>4598</td>\n",
       "      <td>OO</td>\n",
       "      <td>N641CA</td>\n",
       "      <td>4598</td>\n",
       "      <td>13851</td>\n",
       "      <td>OKC</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>14869</td>\n",
       "      <td>SLC</td>\n",
       "      <td>Salt Lake City, UT</td>\n",
       "      <td>839</td>\n",
       "      <td>830.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1028</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>169.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fl_date mkt_unique_carrier branded_code_share mkt_carrier  \\\n",
       "0  2018-12-26                 DL       DL_CODESHARE          DL   \n",
       "\n",
       "   mkt_carrier_fl_num op_unique_carrier tail_num  op_carrier_fl_num  \\\n",
       "0                4598                OO   N641CA               4598   \n",
       "\n",
       "   origin_airport_id origin   origin_city_name  dest_airport_id dest  \\\n",
       "0              13851    OKC  Oklahoma City, OK            14869  SLC   \n",
       "\n",
       "       dest_city_name  crs_dep_time  dep_time  dep_delay  taxi_out  \\\n",
       "0  Salt Lake City, UT           839     830.0       -9.0      15.0   \n",
       "\n",
       "   wheels_off  wheels_on  taxi_in  crs_arr_time  arr_time  arr_delay  \\\n",
       "0       845.0      945.0     25.0          1028    1010.0      -18.0   \n",
       "\n",
       "   cancelled cancellation_code  diverted dup  crs_elapsed_time  \\\n",
       "0        0.0               NaN       0.0   N             169.0   \n",
       "\n",
       "   actual_elapsed_time  air_time  flights  distance  carrier_delay  \\\n",
       "0                160.0     120.0      1.0     866.0            NaN   \n",
       "\n",
       "   weather_delay  nas_delay  security_delay  late_aircraft_delay  \\\n",
       "0            NaN        NaN             NaN                  NaN   \n",
       "\n",
       "   first_dep_time  total_add_gtime  longest_add_gtime  no_name  \n",
       "0             NaN              NaN                NaN      NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(250000, 42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is for the dataset you want to investigate\n",
    "flights = pd.read_csv('data/flights250K.csv', index_col=0)\n",
    "flights.head(1)\n",
    "flights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-folder",
   "metadata": {},
   "source": [
    "Build df based on columns we will use in transformation - Data Cleaning and Feature Implementation\n",
    "\n",
    "**See option A or B in first rows to build df based on training or test dataset** (for copy pasta later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "selective-oriental",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245714, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>op_unique_carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>crs_dep_time</th>\n",
       "      <th>crs_arr_time</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>delay_range</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>origin_precip_monthly</th>\n",
       "      <th>origin_snow_monthly</th>\n",
       "      <th>origin_wind_monthly</th>\n",
       "      <th>origin_cloud_monthly</th>\n",
       "      <th>dest_precip_monthly</th>\n",
       "      <th>dest_snow_monthly</th>\n",
       "      <th>dest_wind_monthly</th>\n",
       "      <th>dest_cloud_monthly</th>\n",
       "      <th>airline_delay</th>\n",
       "      <th>haul_length</th>\n",
       "      <th>dep_timeday</th>\n",
       "      <th>arr_timeday</th>\n",
       "      <th>delay_dep_h</th>\n",
       "      <th>delay_arr_h</th>\n",
       "      <th>busy_origin</th>\n",
       "      <th>busy_dest</th>\n",
       "      <th>origin_delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>253</td>\n",
       "      <td>327</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>169.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>329</td>\n",
       "      <td>331</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>75.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>94</td>\n",
       "      <td>316</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>185.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>93</td>\n",
       "      <td>72</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>99.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>136</td>\n",
       "      <td>238</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>92</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>123.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>22</td>\n",
       "      <td>167</td>\n",
       "      <td>214</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>142.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22</td>\n",
       "      <td>310</td>\n",
       "      <td>92</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>140.0</td>\n",
       "      <td>853.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>219</td>\n",
       "      <td>180</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>164.0</td>\n",
       "      <td>944.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>19</td>\n",
       "      <td>249</td>\n",
       "      <td>327</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>115.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   op_unique_carrier  origin  dest  crs_dep_time  crs_arr_time  \\\n",
       "0                 19     253   327             9            10   \n",
       "1                 24     329   331            17            18   \n",
       "2                 24      94   316             8            10   \n",
       "3                  2      93    72             7             9   \n",
       "4                 19     136   238             5             6   \n",
       "5                 19      46    92            18            20   \n",
       "6                 22     167   214            17            20   \n",
       "7                 22     310    92            14            17   \n",
       "8                  8     219   180            16            18   \n",
       "9                 19     249   327            13            16   \n",
       "\n",
       "   crs_elapsed_time  distance  delay_range  month  day  weekday  \\\n",
       "0             169.0     866.0            0     12   26        2   \n",
       "1              75.0     342.0            2      4   18        3   \n",
       "2             185.0    1024.0            0     10   30        1   \n",
       "3              99.0     331.0            0      3    9        5   \n",
       "4              80.0     284.0            0      3   29        4   \n",
       "5             123.0     649.0            0     12   21        5   \n",
       "6             142.0     758.0            0     12    1        5   \n",
       "7             140.0     853.0            0      2    8        3   \n",
       "8             164.0     944.0            0      1   31        2   \n",
       "9             115.0     588.0            0      3    1        4   \n",
       "\n",
       "   origin_precip_monthly  origin_snow_monthly  origin_wind_monthly  \\\n",
       "0                    0.0                  0.0                  0.0   \n",
       "1                    1.0                  0.0                  0.0   \n",
       "2                    0.0                  1.0                  3.0   \n",
       "3                    0.0                  0.0                  2.0   \n",
       "4                    0.0                  0.0                  0.0   \n",
       "5                    0.0                  0.0                  2.0   \n",
       "6                    1.0                  0.0                  0.0   \n",
       "7                    1.0                  0.0                  3.0   \n",
       "8                    0.0                  0.0                  1.0   \n",
       "9                    0.0                  0.0                  0.0   \n",
       "\n",
       "   origin_cloud_monthly  dest_precip_monthly  dest_snow_monthly  \\\n",
       "0                   0.0                  0.0                1.0   \n",
       "1                   3.0                  0.0                0.0   \n",
       "2                   1.0                  1.0                0.0   \n",
       "3                   3.0                  0.0                0.0   \n",
       "4                   0.0                  0.0                2.0   \n",
       "5                   1.0                  0.0                1.0   \n",
       "6                   3.0                  0.0                0.0   \n",
       "7                   2.0                  0.0                1.0   \n",
       "8                   1.0                  0.0                1.0   \n",
       "9                   1.0                  0.0                0.0   \n",
       "\n",
       "   dest_wind_monthly  dest_cloud_monthly  airline_delay  haul_length  \\\n",
       "0                0.0                 3.0              1            0   \n",
       "1                2.0                 1.0              2            0   \n",
       "2                1.0                 2.0              2            1   \n",
       "3                1.0                 2.0              2            0   \n",
       "4                3.0                 2.0              1            0   \n",
       "5                3.0                 1.0              1            0   \n",
       "6                1.0                 1.0              2            0   \n",
       "7                3.0                 1.0              2            0   \n",
       "8                3.0                 2.0              1            0   \n",
       "9                0.0                 0.0              1            0   \n",
       "\n",
       "   dep_timeday  arr_timeday  delay_dep_h  delay_arr_h  busy_origin  busy_dest  \\\n",
       "0            1            1            0            0            3          3   \n",
       "1            2            3            3            2            3          3   \n",
       "2            1            1            0            0            4          4   \n",
       "3            1            1            0            0            3          4   \n",
       "4            1            1            0            1            1          3   \n",
       "5            3            3            3            3            3          4   \n",
       "6            2            3            3            3            3          3   \n",
       "7            2            2            1            1            3          4   \n",
       "8            2            3            2            2            3          3   \n",
       "9            2            2            1            1            3          3   \n",
       "\n",
       "   origin_delay  \n",
       "0             1  \n",
       "1             1  \n",
       "2             2  \n",
       "3             2  \n",
       "4             1  \n",
       "5             0  \n",
       "6             3  \n",
       "7             2  \n",
       "8             3  \n",
       "9             2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(245034, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A - if this is a training dataset, we need arr_delay as our target variable so use this first block of code\n",
    "model_df = flights[flights['cancelled'] == 0][['arr_delay','fl_date','op_unique_carrier','origin','dest','crs_dep_time','crs_arr_time','crs_elapsed_time','distance']]\n",
    "# B - if this is a testing dataset, we will not have arr_delay and cannot include it\n",
    "#model_df = flights[['tail_num','op_carrier_fl_num','fl_date','op_unique_carrier','origin','dest','crs_dep_time','crs_arr_time','crs_elapsed_time','distance']]\n",
    "model_df.shape\n",
    "# first regression will be simple-- is the flight going to be delayed or not?\n",
    "if 'arr_delay' in model_df:\n",
    "    model_df.dropna(subset=['arr_delay'], inplace=True)\n",
    "    delay_bin = []\n",
    "    for i in model_df['arr_delay']:\n",
    "        if i <= 5:\n",
    "            delay_bin.append(0) # no delay (within 5 minutes)\n",
    "        elif (i > 5) and (i <= 10):\n",
    "            delay_bin.append(1) # expect a 5 to 10 minute delay\n",
    "        elif (i > 10) and (i <= 20):\n",
    "            delay_bin.append(2) # expect a 10 to 20 minute delay\n",
    "        elif (i >= 20) and  (i <= 45):\n",
    "            delay_bin.append(3) # expect a 20 to 45 minute delay\n",
    "        elif (i > 45):\n",
    "            delay_bin.append(4) # expect a 45+ minute delay\n",
    "        \n",
    "    model_df['delay_range'] = delay_bin\n",
    "    model_df.drop(columns='arr_delay', inplace=True)\n",
    "\n",
    "# convert date to datetime in order to grab the month\n",
    "model_df['fl_date'] = pd.to_datetime(model_df['fl_date'])\n",
    "#model_df['year'] = model_df['fl_date'].dt.year # decided I do not want year\n",
    "model_df['month'] = model_df['fl_date'].dt.month\n",
    "model_df['day'] = model_df['fl_date'].dt.day\n",
    "model_df['weekday'] = model_df['fl_date'].dt.dayofweek\n",
    "model_df.drop(columns='fl_date', inplace=True) # this won't be needed after we got month\n",
    "\n",
    "# join weather columns by origin and destination per each monthly average\n",
    "model_df = model_df.merge(weather_df, left_on=['month','origin'], right_on=['month','airport'], how='left')\n",
    "model_df.rename(columns={'mean_precip_monthly':'origin_precip_monthly','mean_snow_monthly':'origin_snow_monthly','mean_wind_monthly':'origin_wind_monthly','mean_cloud_monthly':'origin_cloud_monthly'}, inplace=True)\n",
    "model_df.drop(columns='airport', inplace=True)\n",
    "model_df = model_df.merge(weather_df, left_on=['month','dest'], right_on=['month','airport'], how='left')\n",
    "model_df.rename(columns={'mean_precip_monthly':'dest_precip_monthly','mean_snow_monthly':'dest_snow_monthly','mean_wind_monthly':'dest_wind_monthly','mean_cloud_monthly':'dest_cloud_monthly'}, inplace=True)\n",
    "model_df.drop(columns='airport', inplace=True)\n",
    "model_df = model_df.fillna(0)\n",
    "\n",
    "# set delay rating based on expected performance of the airline\n",
    "model_df = model_df.merge(airline_rating, left_on='op_unique_carrier', right_on='airline', how='left')\n",
    "model_df.drop(columns=['airline'],inplace=True) \n",
    "\n",
    "# obtain haul length of the flight using haul function defined above\n",
    "haul(model_df, 'crs_elapsed_time')\n",
    "# model_df.drop(columns=['crs_elapsed_time'],inplace=True)\n",
    "\n",
    "# new column of categorical time of day information using time_day function defined above as well as expected delays relating to the time of day departure\n",
    "model_df['dep_timeday'] = time_day(model_df, 'crs_dep_time')\n",
    "model_df['arr_timeday'] = time_day(model_df, 'crs_arr_time')\n",
    "model_df = model_df.merge(delay_dep_h, left_on='crs_dep_time', right_on='crs_dep_time', how='left')\n",
    "model_df = model_df.merge(delay_arr_h, left_on='crs_arr_time', right_on='crs_arr_time', how='left')\n",
    "#model_df.drop(columns=['crs_dep_time','crs_arr_time'],inplace=True)\n",
    "\n",
    "# classify the expected traffic of the origin and departure airports\n",
    "model_df = model_df.merge(origin_traffic, left_on='origin', right_on='origin', how='left')\n",
    "model_df = model_df.merge(dest_traffic, left_on='dest', right_on='dest', how='left')\n",
    "model_df['busy_origin'].fillna(value=model_df['busy_origin'].mean(), inplace=True)\n",
    "model_df['busy_dest'].fillna(value=model_df['busy_dest'].mean(), inplace=True)\n",
    "model_df = model_df.merge(origin_delay, left_on='origin', right_on='origin', how='left')\n",
    "#model_df.drop(columns=['origin','dest'],inplace=True)\n",
    "\n",
    "# currently hashed out the dropping of the raw features to test out improved correlations - to keep cat feats we need to encode\n",
    "# label encode values for identification of the flight later\n",
    "le = preprocessing.LabelEncoder()\n",
    "model_df['op_unique_carrier'] = le.fit_transform(model_df['op_unique_carrier'].values)\n",
    "model_df['origin'] = le.fit_transform(model_df['origin'].values)\n",
    "model_df['dest'] = le.fit_transform(model_df['dest'].values)\n",
    "\n",
    "# have a look at the dataset\n",
    "model_df.head(10)\n",
    "model_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-cookbook",
   "metadata": {},
   "source": [
    "Import More Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "convinced-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import seaborn as sns; sns.set(style='darkgrid', context='talk')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-morning",
   "metadata": {},
   "source": [
    "Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "portable-conversion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobustScaler()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'delay_range' in model_df: # training dataset\n",
    "    X = model_df.drop(columns=['delay_range'])\n",
    "else: # testset\n",
    "    X = model_df\n",
    "y = model_df['delay_range']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-turner",
   "metadata": {},
   "source": [
    "HERE WE ARE RUNNING ONLY FOR DELAY RANGE -- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "clinical-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataset into an optimized data structure called Dmatrix that XGBoost supports and \n",
    "## gives it acclaimed performance and efficiency gains.\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "first-northwest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[00:04:38] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[00:04:39] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "CPU times: user 7min 28s, sys: 1.61 s, total: 7min 30s\n",
      "Wall time: 37min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7fce8985ae50>,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=0.02,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing...\n",
       "                                           random_state=None, reg_alpha=None,\n",
       "                                           reg_lambda=None,\n",
       "                                           scale_pos_weight=None, silent=True,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=4,\n",
       "                   param_distributions={'colsample_bytree': [0.6, 0.8, 1.0],\n",
       "                                        'gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                                        'max_depth': [3, 4, 5],\n",
       "                                        'min_child_weight': [1, 5, 10],\n",
       "                                        'subsample': [0.6, 0.8, 1.0]},\n",
       "                   random_state=1001, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "folds = 3 # start with 3, move up to 5 to get better after it finishes\n",
    "param_comb = 5 # how many different combinations should be picked randomly out of our total\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "random_search = RandomizedSearchCV(xgb, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(X_train,y_train), verbose=3, random_state=1001 )\n",
    "\n",
    "# Here we go\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_tree = GridSearchCV(RandomForestClassifier(), tree_params, cv=3, verbose=1, n_jobs=-1)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "forest = grid_tree.best_estimator_\n",
    "forest.best_params_\n",
    "forest_score = cross_val_score(forest, X_train, y_train, cv=3)\n",
    "print('Random Forest Classifier Cross Validation Score: ', round(forest_score.mean() * 100, 2).astype(str) + '%')\n",
    "print(\"Training Score: \", round(grid_tree.best_score_,2))\n",
    "\n",
    "filename = 'model2_randforest_delayrange.sav'\n",
    "pickle.dump(logreg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-fitness",
   "metadata": {},
   "source": [
    "If Re-Running: Load from PICKLE + change forest in following cells to re_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from pickle\n",
    "re_forest = pickle.load(open(filename, 'rb'))\n",
    "result = re_forest.score(X_test, y_test)\n",
    "print('Re-Loaded from Pickle: ', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_forest = forest.predict(X_test)\n",
    "y_forest_proba = forest.predict_proba(X_test)\n",
    "print('\\nRandom Forest Classifier - y_test')\n",
    "metrics.confusion_matrix(y_test, y_forest)\n",
    "print('AUC Score \\t{:.2f}\\n'.format(metrics.roc_auc_score(y_test, y_forest_proba, multi_class='ovr', average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infrared-arcade",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Alike how we predicted the whole of X in order to proceed into the second model, we need to go back and now train the entire model on the historical flights information and predict on the flight_test information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "flighttest = pd.read_csv('data/flighttest.csv')\n",
    "flighttest.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHL_Bootcamp",
   "language": "python",
   "name": "lhl_bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
